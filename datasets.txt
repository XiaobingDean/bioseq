# Datasets

DNA:
    RefSeq (all species)
        For RefSeq, this also means that the genome that the sequence comes from can be used as annotation.
        Also, for all bacterial species, gene finding is effectively a solved problem and we can
        separate coding/non-coding regions well for them.
        Effectively, we wouldn't have gene annotations for the eukaryotes which don't have
        RefSeq annotation batches complete, which is relatively fewer of them.

        Another way of thinking about these sequences is that they belong in a phylogeny of species,
        but they also exist in a phylogeny of sequences which have tasks.

Human Variation Data:
    100K genomes
    1K genomes
    dbSNP (only human, but still relevant to many)
    clinVar, etc.


Annotations (DNA):
    RefSeq has annotations in GFF format for only about 150 well-characterized genomes
    Goals could be to generalize genome annotation from only these genomes
    Or we could use categories for contrastive training
    Can also use Dfam to include repetitive stuff

    Additionally, DNA from coding sequences can be annotated with information from the Protein sequences.


Annotations (protein):
    Families
    Protein domain decompositon (PFam)
    GO annotation (Gene Ontology)
    See https://www.biorxiv.org/content/10.1101/2020.07.12.199554v2.full.pdf
    For some of these, some information is available:
    structure, contact, homology, fluorescence, stability, all of which are collected easily by TAPE
        https://github.com/songlab-cal/tape


# Jobs to attempt

Things we can try:
    - Improved results with importance-sampled gradient descent
        - Can we do any better than Martin and all did by accounting for diversity in the sequences?
    - Improved results with contrastive pre-training
        - See if using contrastive objectives and smart selection of pairs can get us something cool.
        - Maybe LOF SNPs can be a good "hard" negative case for contrastive pretraining
    - Architecture changes to attempt to accomplish the same tasks with smaller models.
        - Multiscale attention
    - Domain adaptation: can we infuse protein information into DNA?
    - Model compression: student-teacher or similar attempts to shrink enormous models
                         to see if we can get a model that's small enough to be useful.

I'd like to aim for something simpler and short to just get a first attempt.



Bottom of the barrel/ignore what's below:


Enhancers:
    Predict changes in activity based on sequence
    https://academic.oup.com/nar/article/48/D1/D51/5608998, https://www.biorxiv.org/content/10.1101/2021.04.07.438649v1.full.pdf
    This is out there
