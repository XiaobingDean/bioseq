linear_attention_transformer
fast_transformer_pytorch
einops
x-transformers>=0.19
entmax
product-key-memory
local-attention
numpy
pybind11==2.7.1
feedback-transformer-pytorch
memcnn
e2cnn
